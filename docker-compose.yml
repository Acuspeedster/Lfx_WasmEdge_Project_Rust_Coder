version: '3'

services:
  api:
    build: .
    ports:
      - "8000:8000"
    environment:
      - LLM_API_KEY=${LLM_API_KEY}
      - LLM_API_BASE=${LLM_API_BASE:-https://coder.gaia.domains/v1}
      - LLM_MODEL=${LLM_MODEL:-Qwen2.5-Coder-32B-Instruct-Q5_K_M}
      - LLM_EMBED_MODEL=${LLM_EMBED_MODEL:-nomic-embed}
      - LLM_EMBED_SIZE=${LLM_EMBED_SIZE:-768}
      - QDRANT_HOST=qdrant
      - QDRANT_PORT=6333
    depends_on:
      - qdrant

  mcp-server:
    build:
      context: .
      dockerfile: Dockerfile
    environment:
      - MCP_TRANSPORT=sse
      - MCP_HOST=0.0.0.0
      - MCP_PORT=3001
      - LLM_API_KEY=${LLM_API_KEY}
      - QDRANT_HOST=qdrant
      - QDRANT_PORT=6333
    command: python -m examples.run_mcp_server
    volumes:
      - .:/app
    depends_on:
      - qdrant

  mcp-proxy:
    image: ghcr.io/microsoft/mcp-proxy:latest
    ports:
      - "3000:3000"
    command: http://mcp-server:3001/sse --port 3000 --host 0.0.0.0 --allow-origin="*"
    depends_on:
      - mcp-server